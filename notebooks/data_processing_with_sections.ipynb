{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to do\n",
    "#### General Notes\n",
    "- `airline_sentiment` and possibly `airline_sentiment_confidence` are target columns (the latter cannot be in traning data)\n",
    "- Remove instance of `\"@airline\"` tags from text \n",
    "\n",
    "####  How to handle each column\n",
    "**Numerical Columns**\n",
    "- `negativereason_confidence` -- fill missing data with 0\n",
    "- `retweet_count` -- remove, almost 100% is just 0\n",
    "\n",
    "**Categorical Columns**\n",
    "- `negativereason` -- one hot encode top K reasons +1 column for \"other\"\n",
    "- `airline` -- remove or one hot encode with \"other\" column\n",
    "- `airline_sentiment_gold` -- remove, almost 100% missing data\n",
    "- `name` -- remove, unique data\n",
    "- `negative_reason_gold` -- remove, almost 100% missing data\n",
    "- `tweet_location` -- remove or one hot encode with \"other\" column\n",
    "\n",
    "**Other Columns**\n",
    "- `tweet_coord` -- remove, almost 100% missing data\n",
    "- `user_timezone` -- remove, a lot of missing and correlates with location\n",
    "- `tweet_created` -- convert to columns: day of year (sin/cos), day of week, time of day (sin/cos)\n",
    "- `text` -- sklearn.feature_extraction.text -> CountVectorizer (?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Data Collection and Preparation\n",
    "\n",
    "**Goal**: Gather and perform an initial analysis of publicly available datasets containing labeled texts with sentiment (positive, negative, neutral) in both Polish and English.\n",
    "\n",
    "**Dataset**:\n",
    "- **E2 - Twitter US Airline Sentiment**:\n",
    "  - [Link to Dataset](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment)\n",
    "\n",
    "**Tasks**:\n",
    "1. Conduct an initial data exploration (e.g., number of examples, class distribution).\n",
    "2. Prepare the data for modeling:\n",
    "   - Handle missing data.\n",
    "   - Split the data into training and test sets.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 \n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from src.transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('../data/Tweets.csv')\n",
    "    df = df.drop(columns=['tweet_id'])\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.1, stratify=df[['airline_sentiment']], random_state=0)\n",
    "\n",
    "    X_train = df_train.drop(columns=['airline_sentiment', 'airline_sentiment_confidence'])\n",
    "    y_train = df_train[['airline_sentiment']]\n",
    "\n",
    "    X_test = df_test.drop(columns=['airline_sentiment', 'airline_sentiment_confidence'])\n",
    "    y_test = df_test[['airline_sentiment']]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lb364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir when are you releasing your flig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 01:04:19 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10475</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amy_endres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways can you help us figure out our corr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 14:47:33 -0800</td>\n",
       "      <td>cincinnati, ohio</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13829</th>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JoeMcMullenJr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir I paid extra $ for my seat &amp;amp; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 19:54:22 -0800</td>\n",
       "      <td>MA</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ft_tyman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue could I get a free flight to Vegas si...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 21:18:51 -0800</td>\n",
       "      <td>NBMA</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dmb41shows</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united flight 4841...3 gate changes on top of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 17:07:17 -0800</td>\n",
       "      <td>Pursuit of Happiness</td>\n",
       "      <td>Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AmericanNarad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united does this process ever end? Still wait...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 07:36:54 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kklausser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Just did, thanks for checking! :)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 13:51:23 -0800</td>\n",
       "      <td>Jacksonville, FL</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dctimes2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways despite mechanical issues and many ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 13:40:50 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neelaybhatt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir Thx Ops Agt Rich Westagard n Fli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 00:00:09 -0800</td>\n",
       "      <td>Indianapolis, USA</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gerryrard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Your social listening capabilities are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 15:31:49 -0800</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13176 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               negativereason  negativereason_confidence     airline  \\\n",
       "5752                      NaN                        NaN   Southwest   \n",
       "10475                     NaN                        NaN  US Airways   \n",
       "13829              Bad Flight                     0.6852    American   \n",
       "8436                      NaN                        NaN       Delta   \n",
       "3233               Can't Tell                     0.6563      United   \n",
       "...                       ...                        ...         ...   \n",
       "622    Customer Service Issue                     1.0000      United   \n",
       "3730                      NaN                        NaN      United   \n",
       "9925                      NaN                        NaN  US Airways   \n",
       "6069                      NaN                        NaN   Southwest   \n",
       "2280   Customer Service Issue                     0.6571      United   \n",
       "\n",
       "      airline_sentiment_gold           name negativereason_gold  \\\n",
       "5752                     NaN          Lb364                 NaN   \n",
       "10475                    NaN     amy_endres                 NaN   \n",
       "13829                    NaN  JoeMcMullenJr                 NaN   \n",
       "8436                     NaN       ft_tyman                 NaN   \n",
       "3233                     NaN     dmb41shows                 NaN   \n",
       "...                      ...            ...                 ...   \n",
       "622                      NaN  AmericanNarad                 NaN   \n",
       "3730                     NaN      kklausser                 NaN   \n",
       "9925                     NaN       dctimes2                 NaN   \n",
       "6069                     NaN    neelaybhatt                 NaN   \n",
       "2280                     NaN      gerryrard                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "5752               0  @SouthwestAir when are you releasing your flig...   \n",
       "10475              0  @USAirways can you help us figure out our corr...   \n",
       "13829              0  @AmericanAir I paid extra $ for my seat &amp; ...   \n",
       "8436               0  @JetBlue could I get a free flight to Vegas si...   \n",
       "3233               0  @united flight 4841...3 gate changes on top of...   \n",
       "...              ...                                                ...   \n",
       "622                0  @united does this process ever end? Still wait...   \n",
       "3730               0          @united Just did, thanks for checking! :)   \n",
       "9925               0  @USAirways despite mechanical issues and many ...   \n",
       "6069               0  @SouthwestAir Thx Ops Agt Rich Westagard n Fli...   \n",
       "2280               0  @united Your social listening capabilities are...   \n",
       "\n",
       "      tweet_coord              tweet_created        tweet_location  \\\n",
       "5752          NaN  2015-02-20 01:04:19 -0800                   NaN   \n",
       "10475         NaN  2015-02-21 14:47:33 -0800      cincinnati, ohio   \n",
       "13829         NaN  2015-02-22 19:54:22 -0800                    MA   \n",
       "8436          NaN  2015-02-18 21:18:51 -0800                  NBMA   \n",
       "3233          NaN  2015-02-19 17:07:17 -0800  Pursuit of Happiness   \n",
       "...           ...                        ...                   ...   \n",
       "622           NaN  2015-02-24 07:36:54 -0800                   NaN   \n",
       "3730          NaN  2015-02-18 13:51:23 -0800      Jacksonville, FL   \n",
       "9925          NaN  2015-02-22 13:40:50 -0800                   NaN   \n",
       "6069          NaN  2015-02-19 00:00:09 -0800     Indianapolis, USA   \n",
       "2280          NaN  2015-02-21 15:31:49 -0800         New York City   \n",
       "\n",
       "                    user_timezone  \n",
       "5752                          NaN  \n",
       "10475                         NaN  \n",
       "13829  Eastern Time (US & Canada)  \n",
       "8436   Eastern Time (US & Canada)  \n",
       "3233                       Hawaii  \n",
       "...                           ...  \n",
       "622        Atlantic Time (Canada)  \n",
       "3730   Eastern Time (US & Canada)  \n",
       "9925   Eastern Time (US & Canada)  \n",
       "6069   Eastern Time (US & Canada)  \n",
       "2280   Eastern Time (US & Canada)  \n",
       "\n",
       "[13176 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_data()\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Stage 2: Building a Simple Sentiment Analysis Model\n",
    "\n",
    "**Goal**: Develop a basic classification model without advanced variable transformations.\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "1. **Basic Text Processing**:\n",
    "   - Convert text to lowercase.\n",
    "   - Remove punctuation and special characters.\n",
    "   - Remove stop words.\n",
    "   - Tokenization.\n",
    "   \n",
    "2. **Text Representation**:\n",
    "   - Use Bag-of-Words (BoW) or TF-IDF to transform text into feature vectors.\n",
    "\n",
    "3. **Model Training**:\n",
    "   - Apply simple classifiers, such as:\n",
    "     - Naive Bayes classifier.\n",
    "     - Logistic regression.\n",
    "     - Decision trees.\n",
    "   - Train the model on the training set.\n",
    "\n",
    "4. **Model Evaluation**:\n",
    "   - Test the model on the test set.\n",
    "   - Calculate metrics: AUC/GINI, accuracy, precision, recall, F1-score.\n",
    "   - Analyze the confusion matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2\n",
    "columns_to_drop = ['retweet_count', 'airline_sentiment_gold', 'negativereason_gold', 'tweet_coord', 'name', 'user_timezone']\n",
    "columns_to_fill_zero = ['negativereason_confidence']\n",
    "columns_to_fill_unknown = ['negativereason', 'tweet_location']\n",
    "columns_to_ohe = ['negativereason', 'airline', 'tweet_location']\n",
    "\n",
    "column_order_after_transform = \\\n",
    "    columns_to_fill_zero \\\n",
    "    + columns_to_fill_unknown \\\n",
    "    + ['airline', 'text', 'tweet_created']\n",
    "column_idx = lambda c : column_order_after_transform.index(c)\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('drop', DropColumnTransformer(columns_to_drop)),\n",
    "    ('fill_missing', \n",
    "        ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('fill_zero', SimpleImputer(strategy='constant', fill_value=0), columns_to_fill_zero),\n",
    "                ('fill_other', SimpleImputer(strategy='constant', fill_value='Unknown'), columns_to_fill_unknown),\n",
    "                \n",
    "            ], \n",
    "            remainder='passthrough')),\n",
    "    ('encode', ColumnTransformer(transformers=[\n",
    "        ('ohe', OneHotEncoder(\n",
    "            handle_unknown='infrequent_if_exist', \n",
    "            max_categories=3, \n",
    "            sparse_output=False), \n",
    "            list(map(column_idx, columns_to_ohe))),\n",
    "        ('time', TimeTransformer(), list(map(column_idx, ['tweet_created']))),\n",
    "        ('text', TextTransformer(), list(map(column_idx, ['text'])))\n",
    "    ],\n",
    "    remainder='passthrough'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Stage 3: Developing an Advanced Sentiment Analysis Model\n",
    "\n",
    "**Goal**: Build a more advanced model, considering detailed data cleaning, transformations, and the use of advanced modeling techniques.\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "1. **Advanced Data Processing and Cleaning**:\n",
    "   - Handle emoticons and emojis.\n",
    "   - Correct spelling errors.\n",
    "   - Apply stemming or lemmatization.\n",
    "   - Consider negations in the text (e.g., \"not good\" vs. \"bad\").\n",
    "   - Remove duplicates.\n",
    "   - Normalize text (e.g., expand abbreviations).\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Create additional features such as:\n",
    "     - N-grams (bigrams, trigrams).\n",
    "     - Word frequency.\n",
    "     - Sentiment indicators based on dictionaries.\n",
    "     - Use word embeddings (e.g., Word2Vec, GloVe).\n",
    "\n",
    "3. **Advanced Modeling Techniques**:\n",
    "   - Apply more complex models, such as:\n",
    "     - Support Vector Machines (SVM).\n",
    "     - Random Forest.\n",
    "     - Gradient Boosting (e.g., XGBoost).\n",
    "     - Neural Networks:\n",
    "       - Recurrent Neural Networks (RNN, LSTM).\n",
    "       - Convolutional Neural Networks (CNN).\n",
    "       - Transformer models (e.g., BERT, RoBERTa).\n",
    "\n",
    "4. **Hyperparameter Tuning**:\n",
    "   - Use techniques like Grid Search or Random Search for model optimization.\n",
    "\n",
    "5. **Model Evaluation**:\n",
    "   - Use cross-validation for model evaluation.\n",
    "   - Compare results with the simple model:\n",
    "     - Did advanced techniques improve the performance?\n",
    "   - Analyze cases where the model performs better or worse.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Comparison with LLM Models (e.g., OpenAI)\n",
    "\n",
    "**Goal**: Compare the results of custom-built models with those from LLM (Large Language Models).\n",
    "\n",
    "**Tasks**:\n",
    "\n",
    "1. **Developing an LLM Prompt**:\n",
    "   - Create an effective prompt for sentiment analysis. Example:\n",
    "     ```\n",
    "     Analyze the sentiment of the following text and classify it as positive, negative, or neutral:\n",
    "     \"{text}\"\n",
    "     ```\n",
    "\n",
    "2. **Using LLM API**:\n",
    "   - Send test data to the LLM model via API.\n",
    "   - Save LLM model predictions.\n",
    "   - Ensure compliance with LLM usage policies.\n",
    "\n",
    "3. **Analysis and Comparison of Results**:\n",
    "   - Compare evaluation metrics of all models.\n",
    "   - Identify differences in predictions between models.\n",
    "   - Discuss potential reasons for these differences:\n",
    "     - Ability to understand context.\n",
    "     - Handling irony or sarcasm.\n",
    "     - Impact of input data quality.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Enhancing Project Appeal\n",
    "\n",
    "1. **Experimenting with Ensemble Methods**:\n",
    "   - Combine results from different models to improve accuracy (e.g., voting, stacking).\n",
    "\n",
    "2. **Bias and Ethics in AI**:\n",
    "   - Analyze whether models exhibit biases towards certain groups or topics.\n",
    "   - Propose methods to reduce bias in models.\n",
    "\n",
    "3. **Practical Application of Models**:\n",
    "   - Use the models for analyzing current data (e.g., recent tweets on a particular topic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
